[0,0,1563415] 2025-10-08 03:52:44,438 [_training.py] INFO Running step 0 (compilation step)...
[0,0,1563415] 2025-10-08 03:53:38,094 [_training.py] INFO Step 0 (compilation) took 53.6557s
[0,0,1563415] 2025-10-08 03:53:38,223 [_training.py] ERROR Exception during benchmark loop
Traceback (most recent call last):
  File "/home/carlesoctav/personal/fme/src/_training.py", line 724, in benchmark_loop
    progress_bar.update()
  File "/home/carlesoctav/personal/fme/.venv/lib/python3.11/site-packages/tqdm/std.py", line 1242, in update
    self.refresh(lock_args=self.lock_args)
  File "/home/carlesoctav/personal/fme/.venv/lib/python3.11/site-packages/tqdm/std.py", line 1347, in refresh
    self.display()
  File "/home/carlesoctav/personal/fme/.venv/lib/python3.11/site-packages/tqdm/std.py", line 1495, in display
    self.sp(self.__str__() if msg is None else msg)
  File "/home/carlesoctav/personal/fme/.venv/lib/python3.11/site-packages/tqdm/std.py", line 459, in print_status
    fp_write('\r' + s + (' ' * max(last_len[0] - len_s, 0)))
  File "/home/carlesoctav/personal/fme/.venv/lib/python3.11/site-packages/tqdm/std.py", line 452, in fp_write
    fp.write(str(s))
  File "/home/carlesoctav/personal/fme/.venv/lib/python3.11/site-packages/tqdm/utils.py", line 196, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe
[0,0,1563415] 2025-10-08 03:53:38,225 [_training.py] INFO Benchmark loop ended
[0,0,376027] 2025-10-15 03:44:11,567 [_training.py] INFO Running step 0 (compilation step)...
[0,0,376027] 2025-10-15 03:44:11,694 [_training.py] ERROR Exception during benchmark loop
Traceback (most recent call last):
  File "/mnt/carles/fme/src/_training.py", line 744, in benchmark_loop
    module, optimizer, aux = train_step_fn(
                             ^^^^^^^^^^^^^^
  File "/mnt/carles/fme/research/bert-mlm/another_bench.py", line 163, in train_step_fn
    (_, aux), grads = grad_fn(params, batch, key)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/carles/fme/research/bert-mlm/another_bench.py", line 153, in loss_fn_params
    return loss_function(module_inst, optimizer, batch, key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/carles/fme/research/bert-mlm/another_bench.py", line 52, in loss_function
    logits = model(
             ^^^^^^
  File "/mnt/carles/fme/src/models/bert/modeling_bert.py", line 755, in __call__
    sequence_output = self.bert(
                      ^^^^^^^^^^
  File "/mnt/carles/fme/src/models/bert/modeling_bert.py", line 591, in __call__
    hidden_states = self.embeddings(
                    ^^^^^^^^^^^^^^^^
  File "/mnt/carles/fme/src/models/bert/modeling_bert.py", line 98, in __call__
    embeddings = self.dropout(embeddings, key=d_key)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/carles/fme/src/nn/_dropout.py", line 48, in __call__
    if self.inference or self.p == 0.0:
jax.errors.TracerBoolConversionError: Attempted boolean conversion of traced array with shape bool[].
The error occurred while tracing the function train_step_fn at /mnt/carles/fme/research/bert-mlm/another_bench.py:157 for jit. This concrete value was not available in Python because it depends on the value of the argument module.bert.embeddings.dropout.inference.
See https://docs.jax.dev/en/latest/errors.html#jax.errors.TracerBoolConversionError
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
[0,0,376027] 2025-10-15 03:44:11,695 [_training.py] INFO Benchmark loop ended
[0,0,379218] 2025-10-15 03:45:48,260 [_training.py] INFO Running step 0 (compilation step)...
[0,0,379218] 2025-10-15 03:45:48,413 [_training.py] ERROR Exception during benchmark loop
Traceback (most recent call last):
  File "/mnt/carles/fme/src/_training.py", line 744, in benchmark_loop
    module, optimizer, aux = train_step_fn(
                             ^^^^^^^^^^^^^^
  File "/mnt/carles/fme/research/bert-mlm/another_bench.py", line 163, in train_step_fn
    (_, aux), grads = grad_fn(params, batch, key)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/carles/fme/research/bert-mlm/another_bench.py", line 154, in loss_fn_params
    return loss_function(module_inst, optimizer, batch, key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/carles/fme/research/bert-mlm/another_bench.py", line 52, in loss_function
    logits = model(
             ^^^^^^
  File "/mnt/carles/fme/src/models/bert/modeling_bert.py", line 755, in __call__
    sequence_output = self.bert(
                      ^^^^^^^^^^
  File "/mnt/carles/fme/src/models/bert/modeling_bert.py", line 602, in __call__
    hidden_states = self.encoder(
                    ^^^^^^^^^^^^^
  File "/mnt/carles/fme/src/models/bert/modeling_bert.py", line 461, in __call__
    hidden_states = layer_module(
                    ^^^^^^^^^^^^^
  File "/mnt/carles/fme/src/models/bert/modeling_bert.py", line 415, in __call__
    attention_output = self.attention(
                       ^^^^^^^^^^^^^^^
  File "/mnt/carles/fme/src/models/bert/modeling_bert.py", line 286, in __call__
    self_output = self.self(
                  ^^^^^^^^^^
  File "/mnt/carles/fme/src/models/bert/modeling_bert.py", line 191, in __call__
    attn_heads = self.sdpa(
                 ^^^^^^^^^^
  File "/mnt/carles/fme/src/nn/_attention.py", line 129, in __call__
    if self.inference:
jax.errors.TracerBoolConversionError: Attempted boolean conversion of traced array with shape bool[].
The error occurred while tracing the function train_step_fn at /mnt/carles/fme/research/bert-mlm/another_bench.py:158 for jit. This concrete value was not available in Python because it depends on the value of the argument module.bert.encoder.layer[0].attention.self.sdpa.inference.
See https://docs.jax.dev/en/latest/errors.html#jax.errors.TracerBoolConversionError
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
[0,0,379218] 2025-10-15 03:45:48,414 [_training.py] INFO Benchmark loop ended
[0,0,382345] 2025-10-15 03:47:10,874 [_training.py] INFO Running step 0 (compilation step)...
[0,0,385540] 2025-10-15 03:48:46,067 [_training.py] INFO Running step 0 (compilation step)...
[0,0,385540] 2025-10-15 03:49:38,352 [_training.py] INFO Step 0 (compilation) took 52.2819s
[0,0,385540] 2025-10-15 03:49:38,357 [_training.py] INFO Starting JAX profiler trace at step 1
[0,0,385540] 2025-10-15 03:49:50,466 [_training.py] INFO ==============================
[0,0,385540] 2025-10-15 03:49:50,466 [_training.py] INFO ===== Benchmark Results ======
[0,0,385540] 2025-10-15 03:49:50,466 [_training.py] INFO ==============================
[0,0,385540] 2025-10-15 03:49:50,466 [_training.py] INFO Train Step Time (avg): 0.1148s
[0,0,385540] 2025-10-15 03:49:50,467 [_training.py] INFO Train Step Time (median): 0.1105s
[0,0,385540] 2025-10-15 03:49:50,467 [_training.py] INFO Train Step Time (std): 0.0431s
[0,0,385540] 2025-10-15 03:49:50,467 [_training.py] INFO Next Batch Time (avg): 0.0036s
[0,0,385540] 2025-10-15 03:49:50,467 [_training.py] INFO Batches/sec (avg): 8.71
[0,0,385540] 2025-10-15 03:49:50,467 [_training.py] INFO Compile Time: 52.2819s
[0,0,385540] 2025-10-15 03:49:50,468 [_training.py] INFO ==============================
[0,0,385540] 2025-10-15 03:49:50,468 [_training.py] INFO Benchmark loop ended
