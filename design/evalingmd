

train_loop(
    eval = 
)




def eval(
    model,
    logger,
):
    dataset = load_dataset()
    make_datasets() = 





mmm about training loop, i feel like we've a wrong api here for the eval part
sometimes eval has different 

we should've a EvalCallback where consist of


class EvalCallback:
    datasets: list[iterdataset] | dataset
    logger: Logger (same logger as the train)

    def prepare_dataset():
        pass

    def eval_step():
        for dataset in datasets:
            dataset_aux = None
            for batch in dataset:
                aux = self.eval_step(model, optimizer, batch, key)
                dataset_aux = jtu.treemap(self.aux[xx], aux)

            



on_training_start(model, optimizer)
on_training_step_start(model, optimizer, batch, *, step_idx)
on_training_step_end(model, optimizer, batch, aux, *, step_idx) # step metrics

on_training_end(model, optimizer) # aux was

on_validation_start(model, optimizer)


on_validation_step_start(model, optimizer, batch, *, step_idx) (remember step_idx was local eval_step_idx)
on_validation_step_end(model, optimizer, batch, aux, *, step_idx)

on_validation_end(model, optimizer) 


also model checkpoiting should be on on_training_step_end() and on_training_end() (to save the last model)
or on validation_step_end() if we're do checkpoint based on eval results (cannot do both unless you're creating to modelcheckpoint callback)

but the default is on_trainign_step_end()
and we use _every_n_step check to check if we do this thing or not

now the problem is i need metrics for model checkpoint to works
but i dont put metrics inside the on_training_step_end
also if we're using just individual step metrics, i dont think we'll ve a good metric to compare things

what if we do 

on_training_step_start(model, optimizer, batch, *, step_idx)
on_training_step_end(model, optimizer, batch, aux, reduce, *, step_idx) # step metrics
where reduce = is the output of logger.log_scalars 

the think now log_scalars should also store atleast Per-N-step loss, and we can use this Per-N-step loss

reduce = {"loss": 12.5, "per_N_loss": 13.5 } #(loss was step  p_loss)
reduce = {"loss": 12.5, } #(loss was step  p_loss, if step % N-step != 0)

and we monitor this per_N_loss

for eval per_N_* was acutally the entire dataset (but rn we manage this outside the logger) i think
    well move this inside the logger,



no need to flattend the metrics if use Eval

then remove the last_train_logged and last_eval_logged
last_train_logger -> last train step aux
last_eval_logged -> eval metrics (aggregate)



